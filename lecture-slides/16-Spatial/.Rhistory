# check the fit of our lasso
fit_lasso = finalize_lasso |> last_fit(data_split_matrix)
data_split_matrix = as.data.frame.numeric(data_split)
finalize_lasso =
lasso_workflow |>
finalize_workflow(select_best(lasso_cv, metric = 'rmse'))
finalize_lasso
# check the fit of our lasso
fit_lasso = finalize_lasso |> last_fit(data_split_matrix)
data_split_matrix = as.data.frame.numeric_version(data_split)
finalize_lasso =
lasso_workflow |>
finalize_workflow(select_best(lasso_cv, metric = 'rmse'))
# check the fit of our lasso
fit_lasso = finalize_lasso |> last_fit(data_split_matrix)
# check the fit of our lasso
fit_lasso = finalize_lasso |> last_fit(data_split)
fit_lasso |> collect_metrics()
# check the fit of our lasso
data_split_matrix = as.numeric(data_split)
View(data_split)
# check the fit of our lasso
data_split_2 <- mutate_all(data_split, function(x) as.numeric(as.character(x)))
# check the fit of our lasso
data_split_matrix =
fit_lasso = finalize_lasso |> last_fit(data_split)
p_load(tidyverse, tidymodels, skimr, glmnet, kknn, ggplot2, pacman, dplyr)
install.packages("pacman")
install.packages("pacman")
p_load(tidyverse, tidymodels, skimr, glmnet, kknn, ggplot2, pacman, dplyr)
p_load(tidyverse, tidymodels, skimr, glmnet, kknn, ggplot2, pacman, dplyr)
p_load(tidyverse, tidymodels, skimr, glmnet, kknn, ggplot2, pacman, dplyr)
p_load(tidyverse, tidymodels, skimr, glmnet, kknn, ggplot2, pacman, dplyr)
install.packages("pacman")
p_load(tidyverse, tidymodels, skimr, glmnet, kknn, ggplot2, pacman, dplyr)
install.packages("pacman")
p_load(tidyverse, tidymodels, skimr, glmnet, kknn, ggplot2, pacman, dplyr)
library(tidyverse)
library(tidymodels)
library(skimr)
library(glmnet)
library(kknn)
library(ggplot2)
library(pacman)
library(dplyr)
#p_load(tidyverse, tidymodels, skimr, glmnet, kknn, ggplot2, pacman, dplyr)
data(ames)
skim(ames)
ames2 = ames |>
select(-MS_SubClass, -Condition_2, -MS_Zoning, -Alley, -Roof_Matl, -Mas_Vnr_Type, -Electrical, -Functional) |>
mutate(
#id = factor(row_number()),
Ln_Gr_Liv_Area = log(Gr_Liv_Area),
Ln_Sale_Price = log(Sale_Price)
)
set.seed(1441)
data_split = ames2 |> initial_split(prop = 0.8)
data_train = data_split |> training()
data_test  = data_split |> testing()
recipe_all = recipe(Ln_Sale_Price ~ ., data = data_train)
recipe_all |>
#update_role(id, new_role = "ID") |>
step_dummy(all_nominal_predictors(), one_hot=TRUE) |>
step_nzv(all_predictors())  |>
step_naomit(all_nominal_predictors()) |>
step_other(all_nominal_predictors(), threshold = 0.01) |>
step_corr(all_numeric_predictors(), threshold=0.8)
clean_data = recipe_all |> prep() |> juice()
model_lm =
linear_reg() |>
set_engine("lm")
ols_workflow =
workflow() |>                 # Define a workflow
add_model(model_lm) |>        # Choose the model
add_recipe(recipe_all)
#fit our train data
ols_fit = fit(ols_workflow, data = data_train)
#make ols prediction
ols_pred = last_fit(ols_fit, split = data_split)
collect_metrics(ols_pred)
recipe_lasso = recipe(Ln_Sale_Price ~ ., data = data_train)
recipe_lasso |>
step_dummy(all_nominal_predictors(), one_hot=TRUE) |>
step_nzv(all_predictors())  |>
#step_naomit(all_nominal_predictors()) |>
step_other(all_nominal_predictors()) |>
step_poly(c(Year_Built, Lot_Area, Gr_Liv_Area, First_Flr_SF, Total_Bsmt_SF, Bsmt_Unf_SF), degree= 2, role= "predictor") |>
step_corr(all_numeric_predictors())
clean_data_lasso = recipe_lasso |> prep() |> juice()
model_lasso = linear_reg(penalty = tune(), mixture = 1) |>
set_engine("glmnet")
lambdas = 10 ^ seq(from = 1, to = -5, length = 100)
lasso_workflow =
workflow() |>                 # Define a workflow
add_model(model_lasso) |>        # Choose the model
add_recipe(recipe_lasso)
#do some folds
lasso_cv = data_train_matrix |> vfold_cv(v = 10)
#do some folds
lasso_cv = data_train |> vfold_cv(v = 10)
#check and cross validate with the lambda penalty
lasso_cv = lasso_workflow |>
tune_grid(
lasso_cv,
grid = data.frame(penalty = lambdas),
metrics = metric_set(rmse)
)
# I got an error that is making me change my df to a fully numeric matrix here, so I am creating a numeric version of training data
data_train_matrix = data.matrix(data_train)
#make our lasso recipe...honestly I am not going to change the recipe here in case it throws errors again, I think this might be the best recipe I can do to ensure I get some sort of result.
# I got an error that is making me change my df to a fully numeric matrix here, so I am creating a numeric version of training data
data_train_matrix = data.matrix(data_train)
recipe_lasso = recipe(Ln_Sale_Price ~ ., data = data_train_matrix)
recipe_lasso |>
step_dummy(all_nominal_predictors(), one_hot=TRUE) |>
step_nzv(all_predictors())  |>
#step_naomit(all_nominal_predictors()) |>
step_other(all_nominal_predictors()) |>
step_poly(c(Year_Built, Lot_Area, Gr_Liv_Area, First_Flr_SF, Total_Bsmt_SF, Bsmt_Unf_SF), degree= 2, role= "predictor") |>
step_corr(all_numeric_predictors())
clean_data_lasso = recipe_lasso |> prep() |> juice()
model_lasso = linear_reg(penalty = tune(), mixture = 1) |>
set_engine("glmnet")
lambdas = 10 ^ seq(from = 1, to = -5, length = 100)
lasso_workflow =
workflow() |>                 # Define a workflow
add_model(model_lasso) |>        # Choose the model
add_recipe(recipe_lasso)
#do some folds
lasso_cv = data_train_matrix |> vfold_cv(v = 10)
#check and cross validate with the lambda penalty
lasso_cv = lasso_workflow |>
tune_grid(
lasso_cv,
grid = data.frame(penalty = lambdas),
metrics = metric_set(rmse)
)
#see what lambda did the best
lasso_cv |> show_best()
# Plot results
autoplot(lasso_cv, metric = "rmse")
finalize_lasso =
lasso_workflow |>
finalize_workflow(select_best(lasso_cv, metric = 'rmse'))
finalize_lasso
finalize_lasso =
lasso_workflow |>
finalize_workflow(select_best(lasso_cv, metric = "rmse"))
finalize_lasso
# check the fit of our lasso
#data_split_matrix = HELP
fit_lasso = finalize_lasso |> last_fit(data_split)
fit_lasso |> collect_metrics()
# check the fit of our lasso
data_split_matrix = lapply(data_split,as.numeric)
# check the fit of our lasso
data_split_matrix = lapply(data_split,as.numeric(unlist(data_split)))
# check the fit of our lasso
unlist(data_split)
data_split_matrix = lapply(data_split,as.numeric)
data_split_matrix = lapply(data_split,as.numeric)
# check the fit of our lasso
unlist(data_split)
data_split_matrix = lapply(data_split,as.numeric)
# check the fit of our lasso
unlist_data_split = unlist(data_split)
data_split_matrix = lapply(unlist_data_split,as.numeric)
fit_lasso = finalize_lasso |> last_fit(data_split)
fit_lasso = finalize_lasso |> last_fit(unlist_data_split)
fit_lasso |> collect_metrics()
model_net = linear_reg(penalty = tune(), mixture = tune()) |>
set_engine("glmnet")
#make a workflow
```
#make a workflow
workflow_net = workflow() |>
add_recipe(recipe_lasso) |>
add_model(model_net)
#do the cross validation
net_cv = workflow_net |>
tune_grid(
lasso_cv,
grid = grid_regular(mixture(), penalty(), levels = 5:5),
metrics = metric_set(rmse)
)
#do some folds
lasso_folds = data_train |> vfold_cv(v = 10)
#check and cross validate with the lambda penalty
lasso_cv = lasso_workflow |>
tune_grid(
lasso_cv,
grid = data.frame(penalty = lambdas),
metrics = metric_set(rmse)
)
#check and cross validate with the lambda penalty
lasso_cv = lasso_workflow |>
tune_grid(
lasso_folds,
grid = data.frame(penalty = lambdas),
metrics = metric_set(rmse)
)
#do some folds
lasso_folds = data_train_matrix |> vfold_cv(v = 10)
#check and cross validate with the lambda penalty
lasso_cv = lasso_workflow |>
tune_grid(
lasso_folds,
grid = data.frame(penalty = lambdas),
metrics = metric_set(rmse)
)
#see what lambda did the best
lasso_cv |> show_best()
# Plot results
autoplot(lasso_cv, metric = "rmse")
finalize_lasso =
lasso_workflow |>
finalize_workflow(select_best(lasso_cv, metric = "rmse"))
finalize_lasso
# check the fit of our lasso
#HELP>>>
unlist_data_split = unlist(data_split)
data_split_matrix = lapply(unlist_data_split,as.numeric)
fit_lasso = finalize_lasso |> last_fit(unlist_data_split)
fit_lasso = finalize_lasso |> last_fit(data_split)
fit_lasso |> collect_metrics()
fit_lasso = finalize_lasso |> last_fit(unlist_data_split)
finalize_lasso =
lasso_workflow |>
finalize_workflow(select_best(lasso_cv, metric = "rmse"))
finalize_lasso
elastic_folds = data_train |> vfold_cv(v=10)
#do the cross validation
net_cv = workflow_net |>
tune_grid(
elastic_folds,
grid = grid_regular(mixture(), penalty(), levels = 5:5),
metrics = metric_set(rmse)
)
# show best
show_best(net_cv)
#find and use the best model from elasticnet
final_net =
workflow_net |>
finalize_workflow(select_best(net_cv, metric = "rmse"))
final_net
hist(Master_Data$Foreign_born)
library(tidyverse)
library(ggplot2)
library(gganimate)
library(RColorBrewer)
library(readxl)
library(binsreg)
library(tidyr)
library(dplyr)
Master_Data = read_excel("/Users/katelynschmitt/Documents/Econ 560/PROJECT/Master_data.xlsx")
hist(Master_Data$Foreign_born)
Foreign_Hist = hist(Master_Data$Foreign_born)
set wd("/Users/katelynschmitt/Documents/Econ 560/PROJECT/")
setwd()
setwd("/Users/katelynschmitt/Documents/Econ 560/PROJECT/")
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born)) +
geom_histogram() +
geom_vline(aes(xintercept = mean(Foreign_born), color="red", linewidth=2)) + labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in Counties')
Foreign_Hist
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born)) +
geom_histogram() +
geom_vline(aes(xintercept = mean(Foreign_born), color="red", linewidth=.25)) + labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in Counties')
Foreign_Hist
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born)) +
geom_histogram() +
geom_vline(aes(xintercept = mean(Foreign_born), color="red", linewidth=0.25)) + labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in Counties')
Foreign_Hist
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born)) +
geom_histogram(bins=10) +
geom_vline(aes(xintercept = mean(Foreign_born), color="red", linewidth=0.25)) + labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
Foreign_Hist
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born)) +
geom_histogram(bins=100) +
geom_vline(aes(xintercept = mean(Foreign_born), color="red", linewidth=0.25)) + labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
Foreign_Hist
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born)) +
geom_histogram(bins=50) +
geom_vline(aes(xintercept = mean(Foreign_born), color="red", linewidth=0.25)) + labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
Foreign_Hist
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born)) +
geom_histogram(bins=50) +
#geom_vline(aes(xintercept = mean(Foreign_born), color="red", linewidth=0.25))
+ labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born)) +
geom_histogram(bins=50)
#geom_vline(aes(xintercept = mean(Foreign_born), color="red", linewidth=0.25))
+ labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born))
+geom_histogram(bins=50)
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born))+
geom_histogram(bins=50)+
labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
Foreign_Hist
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born))+
geom_histogram(bins=25)+
labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
Foreign_Hist
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born))+
geom_histogram(bins=20)+
labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
Foreign_Hist
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born))+
geom_histogram(bins=35)+
labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
Foreign_Hist
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born))+
geom_histogram(bins=40)+
labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
Foreign_Hist
ggsave(Foreign_Hist, file="foreign.hist.pdf")
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born))+
geom_histogram(bins=40)+
labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
Foreign_Hist
ggsave(Foreign_Hist, file="foreign.hist.pdf")
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born))+
geom_histogram(breaks=40)+
labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
Foreign_Hist
#ggsave(Foreign_Hist, file="foreign.hist.pdf")
#adding a pdf image of pretty hist here
Foreign_Hist = ggplot(data=Master_Data, aes(x=Foreign_born))+
geom_histogram(bins=40)+
labs(x= 'Foreign Born Pop. (%)', y='County Frequency', title = 'Foreign Born Distribution in US Counties')
Foreign_Hist
#ggsave(Foreign_Hist, file="foreign.hist.pdf")
ggsave(Foreign_Hist, file="foreign.hist.png")
![]("/Users/katelynschmitt/Documents/Econ 560/PROJECT/foreign.hist.png)
![Distribution of Foreign Born Population in US Counties](/Users/katelynschmitt/Documents/Econ 560/PROJECT/"foreign.hist.png")
Master_Data |>
group_by(State) |>
mutate(
Foreign_Avg = mean(Foreign_born)
) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') + facet_wrap(~Rural) +ggtitle("Average Foreign Born Pop % in Urban (0) vs. Rural (1) Counties")
Master_Data |>
group_by(State) |>
mutate(
Foreign_Avg = mean(Foreign_born)
) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') + facet_wrap(~Rural) +ggtitle("Average Foreign Born Pop % in Urban (0) vs. Rural (1) Counties") +
coord_flip()
Master_Data |>
group_by(Rural==1)
group_by(State) |>
mutate(
Foreign_Avg = mean(Foreign_born)
) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') + facet_wrap(~Rural) +ggtitle("Average Foreign Born Pop % in Urban (0) vs. Rural (1) Counties") +
coord_flip()
Master_Data |>
group_by(Rural==1) |>
group_by(State) |>
mutate(
Foreign_Avg = mean(Foreign_born)
) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') + facet_wrap(~Rural) +ggtitle("Average Foreign Born Pop % in Urban (0) vs. Rural (1) Counties") +
coord_flip()
Master_Data |>
group_by(State, Rural==0) |>
mutate(
Foreign_Avg = mean(Foreign_born)
) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') + facet_wrap(~Rural) +ggtitle("Average Foreign Born Pop % in Urban (0) vs. Rural (1) Counties") +
coord_flip()
Master_Data |>
group_by(State, Rural==0) |>
mutate(
Foreign_Avg = mean(Foreign_born)
) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') + #facet_wrap(~Rural)
+
ggtitle("Average Foreign Born Pop % in Urban (0) vs. Rural (1) Counties") +
coord_flip()
Master_Data |>
group_by(State, Rural==0) |>
mutate(
Foreign_Avg = mean(Foreign_born)
) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') + #facet_wrap(~Rural) +
ggtitle("Average Foreign Born Pop % in Urban (0) vs. Rural (1) Counties") +
coord_flip()
#where rural==0, so it is a urban county
Master_Data |>
group_by(State, Rural==0) |>
mutate(
Foreign_Avg = mean(Foreign_born)
) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') + #facet_wrap(~Rural) +
ggtitle("Average Foreign Born Pop % in Urban Counties") +
coord_flip()
Rural_Per_Dat = Master_Data |>
aggregate(Foreign_born, list(State), mean())
Rural_Per_Dat = Master_Data |>
aggregate(Master_Data$Foreign_born, list(Master_Data$State), mean())
Rural_Per_Dat = Master_Data |>
aggregate(Master_Data$Foreign_born, by=list(Master_Data$State), FUN=mean)
Rural_Per_Dat =
aggregate(Master_Data$Foreign_born, by=list(Master_Data$State), FUN=mean)
View(Rural_Per_Dat)
Rural_Per_State =
aggregate(Master_Data$Foreign_born, by=list(Master_Data$State), FUN=mean)
Rural_FB_Graph = Rural_Per_State |>
select_if(Rural==0) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') +
ggtitle("Average Foreign Born Pop % in Urban Counties") +
labs(x='Average Foreign Born Pop. per State')
Rural_FB_Graph = Rural_Per_State |>
group_by(Rural) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') +
ggtitle("Average Foreign Born Pop % in Urban Counties") +
labs(x='Average Foreign Born Pop. per State')
Rural_FB_Graph = Rural_Per_State |>
group_by(State) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') +
ggtitle("Average Foreign Born Pop % in Urban Counties") +
labs(x='Average Foreign Born Pop. per State')
Rural_FB_Graph = Master_Data |>
group_by(Rural_Per_State) |>
ggplot(aes(x=State, y = Foreign_Avg)) + geom_bar(stat = 'identity', fill= 'light blue') +
ggtitle("Average Foreign Born Pop % in Urban Counties") +
labs(x='Average Foreign Born Pop. per State')
count(Rural_Per_State)
View(Rural_Per_State)
distinct(State)
distinct(Master_Data$State)
unique(Master_Data$State)
library(sf)
#spatial analysis
install.packages(sf)
#spatial analysis
install.packages("sf")
install.packages("tmap")
install.packages("tmap")
library(sf)
library(tidyverse)
library(tmap)
setwd(/Users/katelynschmitt/Documents/Econ 560/)
setwd("/Users/katelynschmitt/Documents/Econ 560/")
dir("data/california_counties")
counties = st_read("data/california_counties/CaliforniaCounties.shp")
dir("data/california_counties")
setwd("/Users/katelynschmitt/Documents/GitHub/course-materials/lecture-slides/16-Spatial")
dir("data/california_counties")
counties = st_read("data/california_counties/CaliforniaCounties.shp")
plot(counties["MED_AGE"])
counties = st_read("data/california_counties/CaliforniaCounties.shp") |>
st_make_valid()
alameda = counties |> filter(NAME == "Alameda")
#find the area
library(units)
#find the area
install.packages("units")
install.packages("units")
library(units)
set_units(st_area(alameda), km^2)
counties2 = counties |>
cbind(area = set_units(st_area(counties), km^2))
mean(counties2$area)
# Calculate area using data in WGS84 CRS (4326)
counties2$area_wgs84 = set_units(st_area(st_transform(counties, 4326)), km^2)
# Calculate area using data in Web Mercator CRS (3857)
counties2$area_web = set_units(st_area(st_transform(counties, 3857)), km^2)
# Take a look at the results
counties2 |> select(starts_with("area")) |> head()
#load BART rapid transit stations
stations = st_read("data/bart_stations_2019.geojson")
#Calculate distance from each station to the Oakland Airport
st_distance(filter(stations, station_na == "Oakland Airport"), stations)
#load a shapefile of protected areas
protected = st_read("data/protected_areas/CPAD_2020a_units.shp")
# Verify CRS is the same as county
stopifnot(st_crs(protected) == st_crs(alameda))
#map them
tm_shape(alameda) + tm_polygons() +
tm_shape(protected) + tm_polygons(col = "green")
#map them
tm_shape(alameda) + tm_polygons() +
tm_shape(protected) + tm_polygons(col = "green")
#map them
tmap_mode  = "view"
tm_shape(alameda) + tm_polygons() +
tm_shape(protected) + tm_polygons(col = "green")
protected_intersect = st_filter(protected, alameda) # default: st_intersects
protected_within = st_filter(protected, alameda, .predicate = st_within)
tm_shape(alameda) + tm_polygons(alpha = 0.5) +
tm_shape(protected_intersect) + tm_polygons(col = "green", alpha = 0.5) +
tm_shape(protected_within) + tm_polygons(col = "blue", alpha = 0.5)
tm_shape(alameda) + tm_polygons(alpha=0.5) + tm_dots(stations)
library(tmap)
tm_shape(alameda) + tm_polygons(alpha=0.5) + tm_dots(stations)
